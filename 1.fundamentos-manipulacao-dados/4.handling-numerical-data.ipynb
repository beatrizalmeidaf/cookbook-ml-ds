{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Numerical Data\n",
    "\n",
    "---\n",
    "\n",
    "## Diferença entre Normalização e Padronização\n",
    "- **Min-Max Scaling (Normalização)** → Reescala os valores para um intervalo fixo (exemplo: 0 a 1).\n",
    "- **StandardScaler (Padronização)** → Ajusta os valores para terem **média 0 e desvio padrão 1**.\n",
    "\n",
    "Se os dados seguem uma distribuição normal (ou aproximadamente normal), o StandardScaler é a melhor opção, sendo ideal para modelos que assumem essa distribuição, como PCA e Regressão Linear. Já o MinMaxScaler é útil quando o modelo se beneficia de valores em um intervalo fixo, como redes neurais e KNN, pois normaliza os dados para um range específico, preservando a escala original sem alterar a forma da distribuição.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é o Min-Max Scaling?\n",
    "O **Min-Max Scaling** é uma técnica de normalização usada em Machine Learning para **reescalar os valores de uma variável para um intervalo específico**, geralmente entre **0 e 1** ou **-1 e 1**.\n",
    "\n",
    "Ele ajusta os valores de uma feature de forma que **o menor valor se torne 0 e o maior valor se torne 1**, mantendo a mesma distribuição relativa dos dados.\n",
    "\n",
    "---\n",
    "\n",
    "### Por que usar Min-Max Scaling?\n",
    "Muitos algoritmos de Machine Learning, como **Redes Neurais, K-Means e SVM**, funcionam melhor quando os dados estão na **mesma escala**.  \n",
    "Se os valores das variáveis tiverem faixas muito diferentes (por exemplo, uma feature variando de 0 a 1 e outra de 1.000 a 10.000), o modelo pode **dar mais peso para as features com valores maiores**, impactando negativamente no desempenho.\n",
    "\n",
    "### Benefícios do Min-Max Scaling:\n",
    "- **Evita que valores grandes dominem o modelo**.\n",
    "- **Melhora a estabilidade numérica de algoritmos** baseados em gradiente (como Redes Neurais).\n",
    "- **Ajuda modelos de distância (como KNN e K-Means)** a fazer comparações mais justas entre as variáveis.\n",
    "\n",
    "\n",
    "O Min-Max Scaler é essencial para **evitar problemas de escala entre variáveis**, garantindo que o modelo de Machine Learning **aprenda de maneira equilibrada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing \n",
    "\n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1)) # intervalo\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é a Padronização (Standardization)?\n",
    "A **padronização** é uma técnica de transformação de dados usada para ajustar uma feature para ter **média 0 e desvio padrão 1**. Isso garante que os valores sejam comparáveis em termos de quantos desvios padrão estão afastados da média.\n",
    "\n",
    "---\n",
    "\n",
    "### Por que usar StandardScaler?\n",
    "Diferente da normalização (**Min-Max Scaling**), que reescala os valores para um intervalo fixo, a **padronização transforma os dados em uma distribuição com média zero**. Isso é essencial para **modelos baseados em distribuições estatísticas**.\n",
    "\n",
    "### Benefícios da padronização:\n",
    "- **Torna os dados comparáveis**, removendo viés de escala.\n",
    "- **Evita que valores extremos tenham impacto desproporcional**.\n",
    "- **É amplamente usada em modelos estatísticos e Machine Learning**, como:\n",
    "  - **Regressão Linear**\n",
    "  - **PCA (Análise de Componentes Principais)**\n",
    "  - **SVM (Support Vector Machine)**\n",
    "  - **K-Means**\n",
    "  - **Redes Neurais (às vezes, dependendo do caso)**\n",
    "\n",
    "O **StandardScaler** é essencial para tornar os dados comparáveis, removendo influência da escala e garantindo que os modelos estatísticos **aprendam padrões reais, não apenas diferenças de magnitude**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[-1000.1],\n",
    "              [-200.2],\n",
    "              [500.5],\n",
    "              [600.6],\n",
    "              [9000.9]])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0\n",
      "Standard deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", round(standardized.mean()))\n",
    "print(\"Standard deviation:\", standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é a Normalização de Observações?\n",
    "A **normalização** (normalization) é uma técnica que **reescala** os valores de uma observação (linha) para que **tenham um comprimento total de 1**. Isso é feito dividindo cada valor da observação por uma norma específica.\n",
    "\n",
    "Ao contrário de técnicas como MinMaxScaler e StandardScaler, que atuam **nas features (colunas)**, a normalização atua **nas observações (linhas)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Por que usar Normalizer?\n",
    "- **Torna os dados comparáveis em magnitude** independentemente da escala original.\n",
    "- **Útil para dados esparsos ou de alta dimensionalidade**, como:\n",
    "  - **Text Mining (TF-IDF, Bag of Words)**\n",
    "  - **Vetores de características em Machine Learning**\n",
    "  - **Redes Neurais, onde vetores normalizados podem melhorar a estabilidade do treinamento**\n",
    "\n",
    "### Benefícios:\n",
    "- Mantém a **proporção relativa entre os valores** dentro de cada linha.\n",
    "- **Ajuda a evitar que valores grandes dominem o modelo**.\n",
    "- **Útil para algoritmos baseados em similaridade vetorial**, como:\n",
    "  - **KNN (K-Nearest Neighbors)**\n",
    "  - **SVM (Support Vector Machine)**\n",
    "  - **Redes Neurais**\n",
    "  - **Modelos baseados em distâncias (ex: Cosine Similarity)**\n",
    "\n",
    "### **Diferença entre L1 e L2**\n",
    "- **L2 (Euclidiana):** Vetores de magnitude 1 e é útil quando a relação angular entre os pontos é mais importante do que a escala dos valores individuais.\n",
    "- **L1 (Manhattan):** Preserva esparsidade dos dados (mantém zeros intactos), soma total sempre é 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "features = np.array([[0.5, 0.5],\n",
    "                    [1.1, 3.4],\n",
    "                    [1.5, 20.2],\n",
    "                    [1.63, 34.4],\n",
    "                    [10.9, 3.3]])\n",
    "\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "\n",
    "normalizer.transform(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estatistica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
